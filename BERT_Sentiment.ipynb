{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfjdn+Z02yRhgecOYABVWz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sureshora/CUSTOMER/blob/master/BERT_Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "crWUwu_mlMVW",
        "outputId": "5a39eb7c-784c-4051-a892-2b9a07d3e29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install pandas\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Loading Pre-trained BERT Model**"
      ],
      "metadata": {
        "id": "ZQzvZfpHncJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the pre-trained BERT model and tokenizer\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lmm2mgrhn1S0",
        "outputId": "49bbf19c-db6e-4f70-96ac-7677b38d0a46"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Tokenizing Input Text**"
      ],
      "metadata": {
        "id": "gf6MOPOAoSi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_input(text):\n",
        "    inputs = tokenizer.encode_plus(text, add_special_tokens=True, max_length=512, padding ='max_length', truncation=True, return_tensors='pt')\n",
        "    return inputs['input_ids'], inputs['attention_mask']"
      ],
      "metadata": {
        "id": "_n-rLFZQoXTH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Performing Sentiment Analysis**"
      ],
      "metadata": {
        "id": "my2v2llop0NJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(text):\n",
        "    input_ids, attention_mask = tokenize_input(text)\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    scores = outputs[0][0].detach().numpy()\n",
        "    scores = torch.softmax(torch.tensor(scores), dim=0)\n",
        "    return scores\n"
      ],
      "metadata": {
        "id": "Sx780m5KpvVB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_labels = ['very negative','negative', 'neutral', 'positive', 'very positive']"
      ],
      "metadata": {
        "id": "bjlnhkCLqcPb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text):\n",
        "    scores = get_sentiment(text)\n",
        "    sentiment_score = scores.argmax()\n",
        "    sentiment = sentiment_labels[sentiment_score]\n",
        "    return sentiment, scores"
      ],
      "metadata": {
        "id": "a3XiivdTqvF8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Example usage**"
      ],
      "metadata": {
        "id": "QwHvWjOtrEfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" I love this product! It's fantastic.\"\n",
        "sentiment, scores = analyze_sentiment(text)\n",
        "\n",
        "print(f\"For Text Sentiment: {sentiment}\")\n",
        "print(f\"For Text Scores: {scores}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIKhq3xorL3f",
        "outputId": "482d95dd-81dd-4d2f-e7aa-800d4129ea18"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Text Sentiment: very negative\n",
            "For Text Scores: 0.9998825788497925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_labels = ['very negative','negative', 'neutral', 'positive', 'very positive']"
      ],
      "metadata": {
        "id": "Hk7U06txsnXC"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text):\n",
        "    scores = get_sentiment(text)\n",
        "    sentiment_score = scores.argmax()\n",
        "    sentiment = sentiment_labels[sentiment_score]\n",
        "    return sentiment, scores"
      ],
      "metadata": {
        "id": "P7NZP3pDsw7Z"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" I love this product! It's fantastic.\"\n",
        "sentiment, scores = analyze_sentiment(text)\n",
        "print(f\"Sentiment: {sentiment}\")\n",
        "print(f\"Scores: {scores}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b392179-a1df-4eef-c23d-baf4c4e183c5",
        "id": "w_-AfiN0s1yB"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: very negative\n",
            "Scores: tensor([0.5583, 0.4417])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Case II**"
      ],
      "metadata": {
        "id": "6BSTZtf3vzEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# Load sentiment analysis model\n",
        "sentiment_model = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Custom labels\n",
        "sentiment_labels = ['very negative', 'negative', 'neutral', 'positive', 'very positive']\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    # Get model output\n",
        "    result = sentiment_model(text)[0]  # Get the first result (list of dictionaries)\n",
        "\n",
        "    # Convert result to tensor if it is not already\n",
        "    if isinstance(result['score'], torch.Tensor):\n",
        "        probabilities = result['score']\n",
        "    else:\n",
        "        # Handle result as probabilities (fake example)\n",
        "        probabilities = torch.tensor(result['score'])\n",
        "\n",
        "    # Find the index of the maximum probability\n",
        "    max_index = torch.argmax(probabilities)\n",
        "\n",
        "    # Map index to sentiment label\n",
        "    sentiment = sentiment_labels[max_index.item()]\n",
        "    scores = probabilities\n",
        "\n",
        "    return sentiment, scores\n",
        "\n",
        "# Example text\n",
        "text = \"I love this product! It's fantastic.\"\n",
        "sentiment, scores = analyze_sentiment(text)\n",
        "print(f\"Sentiment: {sentiment}\")\n",
        "print(f\"Scores: {scores}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB8G5SswvuA6",
        "outputId": "34833a37-0234-468a-cd0a-e78c56bb0322"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: very negative\n",
            "Scores: 0.9998825788497925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the pre-trained BERT model and tokenizer\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6fe5c5a6-00a7-428b-dbe8-b891dd98ad74",
        "id": "SqRUBUwqOINF"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the default sentiment analysis model\n",
        "sentiment_model = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    result = sentiment_model(text)[0]  # Get the first result (dictionary)\n",
        "\n",
        "    # Get sentiment label and score\n",
        "    sentiment = result['label']  # e.g., 'POSITIVE' or 'NEGATIVE'\n",
        "    score = result['score']  # Probability score\n",
        "\n",
        "    return sentiment, score\n",
        "\n",
        "# Example text\n",
        "text = \"I love this product! It's fantastic.\"\n",
        "sentiment, score = analyze_sentiment(text)\n",
        "print(f\"Sentiment: {sentiment}\")\n",
        "print(f\"Score: {score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USGefCfmPoqi",
        "outputId": "4e1c2b44-ca67-4c58-d874-a50adb60f8e5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: POSITIVE\n",
            "Score: 0.9998825788497925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the default sentiment analysis model\n",
        "sentiment_model = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Define custom labels\n",
        "custom_labels = {\n",
        "    'POSITIVE': 'very positive',  # Or 'positive' based on your need\n",
        "    'NEGATIVE': 'very negative'   # Or 'negative' based on your need\n",
        "}\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    result = sentiment_model(text)[0]  # Get the first result (dictionary)\n",
        "\n",
        "    # Get sentiment label and score\n",
        "    model_sentiment = result['label']  # e.g., 'POSITIVE' or 'NEGATIVE'\n",
        "    score = result['score']  # Probability score\n",
        "\n",
        "    # Map to custom labels\n",
        "    sentiment = custom_labels[model_sentiment]\n",
        "\n",
        "    return sentiment, score\n",
        "\n",
        "# Example text\n",
        "text = \"I love this product! It's fantastic.\"\n",
        "sentiment, score = analyze_sentiment(text)\n",
        "print(f\"Sentiment: {sentiment}\")\n",
        "print(f\"Score: {score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDlf-umSP0hq",
        "outputId": "bd68899b-c42f-4007-b6c1-e57dba45f07f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: very positive\n",
            "Score: 0.9998825788497925\n"
          ]
        }
      ]
    }
  ]
}